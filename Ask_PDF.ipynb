{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KOMPALALOKESH/Ask-PDF/blob/main/Ask_PDF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrgOhk8U4Rpl"
      },
      "source": [
        "# Quickstart: Querying PDF With Astra and LangChain\n",
        "\n",
        "### A question-answering demo using Astra DB and LangChain, powered by Vector Search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqfJKgRM4Rpo"
      },
      "source": [
        "#### Pre-requisites:\n",
        "\n",
        "You need a **_Serverless Cassandra with Vector Search_** database on [Astra DB](https://astra.datastax.com) to run this demo. As outlined in more detail [here](https://docs.datastax.com/en/astra-serverless/docs/vector-search/quickstart.html#_prepare_for_using_your_vector_database), you should get a DB Token with role _Database Administrator_ and copy your Database ID: these connection parameters are needed momentarily.\n",
        "\n",
        "You also need an [OpenAI API Key](https://cassio.org/start_here/#llm-access) for this demo to work.\n",
        "\n",
        "#### What you will do:\n",
        "\n",
        "- Setup: import dependencies, provide secrets, create the LangChain vector store;\n",
        "- Run a Question-Answering loop retrieving the relevant headlines and having an LLM construct the answer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_FeN-Ep4Rpp"
      },
      "source": [
        "Install the required dependencies:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uk0qUhJUQrkO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84946adf-8932-48de-a7c6-a8d87b199541"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m809.1/809.1 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.9/221.9 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m84.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q cassio datasets langchain openai tiktoken"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQQN-L2J4Rpq"
      },
      "source": [
        "Import the packages you'll need:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4qBIihE4Rpq"
      },
      "outputs": [],
      "source": [
        "# LangChain components to use\n",
        "from langchain.vectorstores.cassandra import Cassandra\n",
        "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "\n",
        "# Support for dataset retrieval with Hugging Face\n",
        "from datasets import load_dataset\n",
        "\n",
        "# With CassIO, the engine powering the Astra DB integration in LangChain,\n",
        "# you will also initialize the DB connection:\n",
        "import cassio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIs76OPQ6JyD",
        "outputId": "ec97a92f-7256-4aff-998f-9a1e62b36c3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/232.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PyPDF2 import PdfReader"
      ],
      "metadata": {
        "id": "1itBNL1v6N9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vu2UauiC4Rpr"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqpM6I854Rpr"
      },
      "outputs": [],
      "source": [
        "ASTRA_DB_APPLICATION_TOKEN = \"AstraCS:XeWQjZDMcgsoBNdLLZMxwMyg:d53d0b3e57ca8e6a561594a71dffb343a544dedc7592bfbe845b1387c9304940\" # enter the \"AstraCS:...\" string found in in your Token JSON file\n",
        "ASTRA_DB_ID = \"f65233ab-9320-4614-89bf-2a5c17611055\" # enter your Database ID\n",
        "\n",
        "OPENAI_API_KEY = \"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\" # enter your OpenAI key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1cmD5EF4Rpr"
      },
      "source": [
        "#### Provide your secrets:\n",
        "\n",
        "Replace the following with your Astra DB connection details and your OpenAI API key:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# provide the path of  pdf file/files.\n",
        "pdfreader = PdfReader('budget_speech.pdf')"
      ],
      "metadata": {
        "id": "waVKJW-n6jqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import Concatenate\n",
        "# read text from pdf\n",
        "raw_text = ''\n",
        "for i, page in enumerate(pdfreader.pages):\n",
        "    content = page.extract_text()\n",
        "    if content:\n",
        "        raw_text += content"
      ],
      "metadata": {
        "id": "42BKuFRO6meP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_text"
      ],
      "metadata": {
        "id": "vR41Iq-4ZHnG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "ddf596f9-fdd1-4993-d8c6-6cf9bdb434cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Kompala Lokesh\\n2-318 Anjaneya swamy street, Bangarupeta, Venkatagiri, 524404\\n♂phone+91 8328260402 /envel⌢pekompalalokesh123@gmail.com /linkedinLokesh Kompala /githubKOMPALALOKESH\\nEducation\\nSri Venkateswara University College of Engineering January 2021 – April 2024 Expected\\nBachelor of Science in Computer Science and Engineering – CGPA: 8.21 Tirupati, Andhra Pradesh\\nNarayana Junior College June 2018 – April 2020\\nM. P. C. – CGPA: 9.69 Nellore, Andhra Pradesh\\nNarayana High School April 2018\\nTenth Class – CGPA: 10.0 Nellore, Andhra Pradesh\\nTechnical Skills\\nLanguages/Databases : Python, Java, SQL, MySQL, Postgres, HTML, CSS, Django\\nLibraries/Frameworks : Numpy, Pandas, scikit-learn, Matplotlib, TensorFlow, LLM\\nTools : VS Code, Google Colaboratory, Jupyter Notebook, GIT/GitHub, Tableau, Excel\\nRelevant Coursework\\n•Data Structures\\n•Machine Learning•Data Science\\n•Artificial Intelligence•Java Programming\\n•Feature Engineering•Django\\nProjects\\nCodeGPT |Python, Google Colaboratory, Github - LINK September 2023\\n•Leveraged Bloke Llama CodeGPT pretrained models in Hugging Face for advanced code generation.\\n•Developed and interfaced CodeGPT project seamlessly with Streamlit app for enhanced user experience.\\n•Optimized Bloke Llama CodeGPT models for efficient collaboration, accessibility ,performance and deployed\\non Google Colaboratory.\\nCredit Card Fraud Detect |Python, Google Colaboratory, Github - LINK June 2023\\n•Utilizing machine learning models to estimate non-occurrence probabilities.\\n•Transformed complex data into actionable insights, demonstrating proficiency in predictive modeling .\\nSentiment Analysis |Python, Google Colaboratory, Github - LINK May 2023\\n•Developed highly accurate sentiment analysis, classifying text emotion s with advanced NLP techniques.\\n•High-impact sentiment analysis project, achieving 96% accuracy.\\n•Engineered robust sentiment analysis, achieving exceptional accuracy through thorough optimization and\\nextensive dataset training.\\nCoCurricular / Achievements\\n•Solved 250+ DSA problems in Leetcode , demonstrating strong problem-solving and coding skills.\\n•Secured runner-up position in a data science competition , showcasing effective problem-solving\\nin real-world scenarios.\\n•Earned the AWS Machine Learning Foundations badge , demonstrating proficiency in Machine\\nlearning concepts and skills.\\n•Ranked in the top 30% in the LinkedIn skill assessment badge for Python andmachine learning ,\\nshowcasing proficiency and expertise.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5S0GgIQs4Rps"
      },
      "source": [
        "Initialize the connection to your database:\n",
        "\n",
        "_(do not worry if you see a few warnings, it's just that the drivers are chatty about negotiating protocol versions with the DB.)_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFBR5HnZSPmK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb6a2d02-c4dd-4986-f89f-b6cbc1c77cd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cassandra.cluster:Downgrading core protocol version from 66 to 65 for f65233ab-9320-4614-89bf-2a5c17611055-us-east-2.db.astra.datastax.com:29042:7d1e19c9-12a6-4994-98b3-32954b433065. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 65 to 5 for f65233ab-9320-4614-89bf-2a5c17611055-us-east-2.db.astra.datastax.com:29042:7d1e19c9-12a6-4994-98b3-32954b433065. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "ERROR:cassandra.connection:Closing connection <AsyncoreConnection(139700044123488) f65233ab-9320-4614-89bf-2a5c17611055-us-east-2.db.astra.datastax.com:29042:7d1e19c9-12a6-4994-98b3-32954b433065> due to protocol error: Error from server: code=000a [Protocol error] message=\"Beta version of the protocol used (5/v5-beta), but USE_BETA flag is unset\"\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 5 to 4 for f65233ab-9320-4614-89bf-2a5c17611055-us-east-2.db.astra.datastax.com:29042:7d1e19c9-12a6-4994-98b3-32954b433065. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n"
          ]
        }
      ],
      "source": [
        "cassio.init(token=ASTRA_DB_APPLICATION_TOKEN, database_id=ASTRA_DB_ID)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex7NxZYb4Rps"
      },
      "source": [
        "Create the LangChain embedding and LLM objects for later usage:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TavS0AK2SLrL"
      },
      "outputs": [],
      "source": [
        "llm = OpenAI(openai_api_key=OPENAI_API_KEY)\n",
        "embedding = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HMMx5Pm4Rpt"
      },
      "source": [
        "Create your LangChain vector store ... backed by Astra DB!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bg9VAk4USQvU"
      },
      "outputs": [],
      "source": [
        "astra_vector_store = Cassandra(\n",
        "    embedding=embedding,\n",
        "    table_name=\"qa_mini_demo\",\n",
        "    session=None,\n",
        "    keyspace=None,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "# We need to split the text using Character Text Split such that it sshould not increse token size\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator = \"\\n\",\n",
        "    chunk_size = 800,\n",
        "    chunk_overlap  = 200,\n",
        "    length_function = len,\n",
        ")\n",
        "texts = text_splitter.split_text(raw_text)"
      ],
      "metadata": {
        "id": "9FMAhKr77AVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts[:50]"
      ],
      "metadata": {
        "id": "k8BDHAyT7Gjr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4154210-950e-4d06-a1b9-f7aaec1e1b85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Kompala Lokesh\\n2-318 Anjaneya swamy street, Bangarupeta, Venkatagiri, 524404\\n♂phone+91 8328260402 /envel⌢pekompalalokesh123@gmail.com /linkedinLokesh Kompala /githubKOMPALALOKESH\\nEducation\\nSri Venkateswara University College of Engineering January 2021 – April 2024 Expected\\nBachelor of Science in Computer Science and Engineering – CGPA: 8.21 Tirupati, Andhra Pradesh\\nNarayana Junior College June 2018 – April 2020\\nM. P. C. – CGPA: 9.69 Nellore, Andhra Pradesh\\nNarayana High School April 2018\\nTenth Class – CGPA: 10.0 Nellore, Andhra Pradesh\\nTechnical Skills\\nLanguages/Databases : Python, Java, SQL, MySQL, Postgres, HTML, CSS, Django\\nLibraries/Frameworks : Numpy, Pandas, scikit-learn, Matplotlib, TensorFlow, LLM\\nTools : VS Code, Google Colaboratory, Jupyter Notebook, GIT/GitHub, Tableau, Excel',\n",
              " 'Libraries/Frameworks : Numpy, Pandas, scikit-learn, Matplotlib, TensorFlow, LLM\\nTools : VS Code, Google Colaboratory, Jupyter Notebook, GIT/GitHub, Tableau, Excel\\nRelevant Coursework\\n•Data Structures\\n•Machine Learning•Data Science\\n•Artificial Intelligence•Java Programming\\n•Feature Engineering•Django\\nProjects\\nCodeGPT |Python, Google Colaboratory, Github - LINK September 2023\\n•Leveraged Bloke Llama CodeGPT pretrained models in Hugging Face for advanced code generation.\\n•Developed and interfaced CodeGPT project seamlessly with Streamlit app for enhanced user experience.\\n•Optimized Bloke Llama CodeGPT models for efficient collaboration, accessibility ,performance and deployed\\non Google Colaboratory.\\nCredit Card Fraud Detect |Python, Google Colaboratory, Github - LINK June 2023',\n",
              " 'on Google Colaboratory.\\nCredit Card Fraud Detect |Python, Google Colaboratory, Github - LINK June 2023\\n•Utilizing machine learning models to estimate non-occurrence probabilities.\\n•Transformed complex data into actionable insights, demonstrating proficiency in predictive modeling .\\nSentiment Analysis |Python, Google Colaboratory, Github - LINK May 2023\\n•Developed highly accurate sentiment analysis, classifying text emotion s with advanced NLP techniques.\\n•High-impact sentiment analysis project, achieving 96% accuracy.\\n•Engineered robust sentiment analysis, achieving exceptional accuracy through thorough optimization and\\nextensive dataset training.\\nCoCurricular / Achievements\\n•Solved 250+ DSA problems in Leetcode , demonstrating strong problem-solving and coding skills.',\n",
              " 'extensive dataset training.\\nCoCurricular / Achievements\\n•Solved 250+ DSA problems in Leetcode , demonstrating strong problem-solving and coding skills.\\n•Secured runner-up position in a data science competition , showcasing effective problem-solving\\nin real-world scenarios.\\n•Earned the AWS Machine Learning Foundations badge , demonstrating proficiency in Machine\\nlearning concepts and skills.\\n•Ranked in the top 30% in the LinkedIn skill assessment badge for Python andmachine learning ,\\nshowcasing proficiency and expertise.']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1WK54-74Rpt"
      },
      "source": [
        "### Load the dataset into the vector store\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GX5BECsdSUUM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c3c39a1-3941-410c-9d85-a37093e19b04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inserted 4 headlines.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "astra_vector_store.add_texts(texts[:50])\n",
        "\n",
        "print(\"Inserted %i headlines.\" % len(texts[:50]))\n",
        "\n",
        "astra_vector_index = VectorStoreIndexWrapper(vectorstore=astra_vector_store)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KhVf0kir2Uke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLJp8yPF4Rpt"
      },
      "source": [
        "### Run the QA cycle\n",
        "\n",
        "Simply run the cells and ask a question -- or `quit` to stop. (you can also stop execution with the \"▪\" button on the top toolbar)\n",
        "\n",
        "Here are some suggested questions:\n",
        "- _What is the current GDP?_\n",
        "- _How much the agriculture target will be increased to and what the focus will be_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MbJugrh7SX3C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8129b5c4-89e9-4f45-fa56-cac2d0ee2ad9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Enter your question (or type 'quit' to exit): what is the name of applicant in the document have?\n",
            "\n",
            "QUESTION: \"what is the name of applicant in the document have?\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cassandra.protocol:Server warning: Top-K queries can only be run with consistency level ONE / LOCAL_ONE / NODE_LOCAL. Consistency level LOCAL_QUORUM was requested. Downgrading the consistency level to LOCAL_ONE.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANSWER: \"The name of the applicant in the document is Kompala Lokesh.\"\n",
            "\n",
            "FIRST DOCUMENTS BY RELEVANCE:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cassandra.protocol:Server warning: Top-K queries can only be run with consistency level ONE / LOCAL_ONE / NODE_LOCAL. Consistency level LOCAL_QUORUM was requested. Downgrading the consistency level to LOCAL_ONE.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    [0.8546] \"Kompala Lokesh\n",
            "2-318 Anjaneya swamy street, Bangarupeta, Venkatagiri, 524404\n",
            "♂phone+ ...\"\n",
            "    [0.8517] \"extensive dataset training.\n",
            "CoCurricular / Achievements\n",
            "•Solved 250+ DSA problems in ...\"\n",
            "    [0.8420] \"on Google Colaboratory.\n",
            "Credit Card Fraud Detect |Python, Google Colaboratory, Githu ...\"\n",
            "    [0.8389] \"Libraries/Frameworks : Numpy, Pandas, scikit-learn, Matplotlib, TensorFlow, LLM\n",
            "Tool ...\"\n",
            "\n",
            "What's your next question (or type 'quit' to exit): exit\n",
            "\n",
            "QUESTION: \"exit\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cassandra.protocol:Server warning: Top-K queries can only be run with consistency level ONE / LOCAL_ONE / NODE_LOCAL. Consistency level LOCAL_QUORUM was requested. Downgrading the consistency level to LOCAL_ONE.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANSWER: \"I don't know.\"\n",
            "\n",
            "FIRST DOCUMENTS BY RELEVANCE:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cassandra.protocol:Server warning: Top-K queries can only be run with consistency level ONE / LOCAL_ONE / NODE_LOCAL. Consistency level LOCAL_QUORUM was requested. Downgrading the consistency level to LOCAL_ONE.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    [0.8652] \"extensive dataset training.\n",
            "CoCurricular / Achievements\n",
            "•Solved 250+ DSA problems in ...\"\n",
            "    [0.8601] \"Kompala Lokesh\n",
            "2-318 Anjaneya swamy street, Bangarupeta, Venkatagiri, 524404\n",
            "♂phone+ ...\"\n",
            "    [0.8559] \"Libraries/Frameworks : Numpy, Pandas, scikit-learn, Matplotlib, TensorFlow, LLM\n",
            "Tool ...\"\n",
            "    [0.8547] \"on Google Colaboratory.\n",
            "Credit Card Fraud Detect |Python, Google Colaboratory, Githu ...\"\n",
            "\n",
            "What's your next question (or type 'quit' to exit): quit\n"
          ]
        }
      ],
      "source": [
        "first_question = True\n",
        "while True:\n",
        "    if first_question:\n",
        "        query_text = input(\"\\nEnter your question (or type 'quit' to exit): \").strip()\n",
        "    else:\n",
        "        query_text = input(\"\\nWhat's your next question (or type 'quit' to exit): \").strip()\n",
        "\n",
        "    if query_text.lower() == \"quit\":\n",
        "        break\n",
        "\n",
        "    if query_text == \"\":\n",
        "        continue\n",
        "\n",
        "    first_question = False\n",
        "\n",
        "    print(\"\\nQUESTION: \\\"%s\\\"\" % query_text)\n",
        "    answer = astra_vector_index.query(query_text, llm=llm).strip()\n",
        "    print(\"ANSWER: \\\"%s\\\"\\n\" % answer)\n",
        "\n",
        "    print(\"FIRST DOCUMENTS BY RELEVANCE:\")\n",
        "    for doc, score in astra_vector_store.similarity_search_with_score(query_text, k=4):\n",
        "        print(\"    [%0.4f] \\\"%s ...\\\"\" % (score, doc.page_content[:84]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dSaUPguw389l"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}